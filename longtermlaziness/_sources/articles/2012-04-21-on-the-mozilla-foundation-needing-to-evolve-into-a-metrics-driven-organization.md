---
title: 'On the Mozilla Foundation needing &#8220;to evolve into a metrics-driven organization&#8221;'
author: David Bruant
layout: post
permalink: /?p=317
categories:
  - Uncategorized
---
So apparently, the Mozilla Foundation [needs to evolve into metrics-driven organization][1] (related [video explanations][2] by [Ryan Merkley][3]). This is worrisome.

## Limitations of metrics as success measurement

I&#8217;d like to step back on what success means. Let&#8217;s take the example of a teacher. By measuring what is a teacher considered successful? Good average class grade? Good students mood? Whatever idea you come up with, you&#8217;ll have to acknowledge very soon that either it cannot be measured quantitatively (students mood) or if it can (average grade), it has limitations (grades cannot really be compared if applied on different topics, teachers could be tempted to bias their grade to be seen as more successful).

Being a &#8220;metrics-**driven** organization&#8221; also means that the mission you&#8217;re trying to achieve is reduced to your metrics. I hope I&#8217;m not shocking anyone if I say that this is a wrong idea in many ways. Many things are not accurately &#8220;metricable&#8221;. Acknowledge it and accept it or you&#8217;re just being intellectually dishonest.

## Metrics done right

Metrics in themselves are not an issue. Metrics are necessary for (at least) two reasons: first, it gives an insight to the outside world on what you do, how your activity evolves over time (not only in the numbers but also in the evolution of the metrics you choose). Second, it&#8217;s good for people motivation. Having your success measured and being able to say &#8220;we were there, we are here and we moved toward the right direction&#8221; is a powerful tool. Also, in periods of doubts, it&#8217;s a good thing to have a very concrete answer to &#8220;where are we going now?&#8221;.

What is an issue though is deciding of a metrics and not being crystal clear on where numbers come from, what their source of bias is, what is the limitation of what is being measured. Having a decent study of this prevents (or at least reduces) misinterpretations.

## &#8220;Contributors&#8221;

It has been decided that there will be one metrics: [contributors][1]. Three categories are being considered: coders, templaters, instructors. For each, a brief description is provided. But I&#8217;m sorry, even when making a big effort, I can&#8217;t figure out numbers based on these vague definitions.

The question is being asked at [26&#8217;15&#8221;][4]: how do we define a contributor? I doesn&#8217;t find its answer in the video unfortunately, while it&#8217;s a the core of the issue being discussed. I&#8217;ll try to elaborate on the question and get to the specifics: &#8220;when do we consider that one person is an additional contributor?&#8221;. If never is defined what the definition of &#8220;one more contributor&#8221; is, then the metrics has no meaning and as a consequence, &#8220;being (un)successful&#8221; is meaningless as well.

I&#8217;m not saying it&#8217;s an easy task, but for sure it is a necessary one, so [I set up an Etherpad][5] to try to define what a contributor is. Please join the discussion.

 [1]: http://openmatt.org/wp-content/uploads/2012/04/Apr-2012-MoFo-Board-Slides-SHARE.pdf
 [2]: http://www.youtube.com/watch?v=o85Cr61fwaQ&t=10m40s
 [3]: https://twitter.com/ryanmerkley
 [4]: http://www.youtube.com/watch?v=o85Cr61fwaQ&t=26m15s
 [5]: https://etherpad.mozilla.org/hf2u18lrqJ